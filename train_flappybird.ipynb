{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ed5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\2025\\ML\\flappybird_ai\\venv\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import trange\n",
    "\n",
    "from game.flappy_bird import FlappyBirdEnv\n",
    "from agent.dqn_agent import DQNAgent, DQNConfig\n",
    "CKPT_PATH = \"agent/flappy_dqn_live.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a3d57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = FlappyBirdEnv(seed=42)\n",
    "state_dim = 5\n",
    "action_dim = 2\n",
    "\n",
    "cfg = DQNConfig(\n",
    "\tstate_dim=state_dim,\n",
    "\taction_dim=action_dim,\n",
    "\tgamma=0.99,\n",
    "\tlr=1e-3,\n",
    "\tbatch_size=64,\n",
    "\treplay_size=50_000,\n",
    "\tstart_learning_after=5_000,\n",
    "\ttarget_update_freq=1_000,\n",
    "\teps_start=1.0,\n",
    "\teps_end=0.05,\n",
    "\teps_decay_steps=50_000,\n",
    "\tgradient_clip_norm=5.0,\n",
    ")\n",
    "\n",
    "agent = DQNAgent(cfg)\n",
    "print(\"Using device:\", agent.cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6451b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 59/500 [00:00<00:00, 589.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 10/500 | Return: -64.0 | 50-ep avg: -64.6 | Eps: 0.993\n",
      "Ep 20/500 | Return: -64.0 | 50-ep avg: -64.5 | Eps: 0.986\n",
      "Ep 30/500 | Return: -66.0 | 50-ep avg: -64.8 | Eps: 0.979\n",
      "Ep 40/500 | Return: -65.0 | 50-ep avg: -64.6 | Eps: 0.972\n",
      "Ep 50/500 | Return: -63.0 | 50-ep avg: -64.6 | Eps: 0.965\n",
      "Ep 60/500 | Return: -65.0 | 50-ep avg: -64.7 | Eps: 0.959\n",
      "Ep 70/500 | Return: -65.0 | 50-ep avg: -64.8 | Eps: 0.952\n",
      "Ep 80/500 | Return: -64.0 | 50-ep avg: -64.5 | Eps: 0.945\n",
      "Ep 90/500 | Return: -62.0 | 50-ep avg: -64.5 | Eps: 0.938\n",
      "Ep 100/500 | Return: -65.0 | 50-ep avg: -64.4 | Eps: 0.931\n",
      "Ep 110/500 | Return: -65.0 | 50-ep avg: -64.2 | Eps: 0.924\n",
      "Ep 120/500 | Return: -62.0 | 50-ep avg: -64.0 | Eps: 0.917\n",
      "Ep 130/500 | Return: -66.0 | 50-ep avg: -63.9 | Eps: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 137/500 [00:00<00:00, 460.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 140/500 | Return: -61.0 | 50-ep avg: -63.9 | Eps: 0.902\n",
      "Ep 150/500 | Return: -65.0 | 50-ep avg: -64.0 | Eps: 0.896\n",
      "Ep 160/500 | Return: -65.0 | 50-ep avg: -64.0 | Eps: 0.888\n",
      "Ep 170/500 | Return: -67.0 | 50-ep avg: -64.2 | Eps: 0.882\n",
      "Ep 180/500 | Return: -63.0 | 50-ep avg: -64.6 | Eps: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|███▋      | 186/500 [00:05<00:13, 23.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 190/500 | Return: -58.0 | 50-ep avg: -64.5 | Eps: 0.868\n",
      "Ep 200/500 | Return: -66.0 | 50-ep avg: -64.8 | Eps: 0.861\n",
      "Ep 210/500 | Return: -68.0 | 50-ep avg: -64.7 | Eps: 0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 213/500 [00:08<00:17, 16.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 220/500 | Return: -66.0 | 50-ep avg: -64.8 | Eps: 0.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▌     | 230/500 [00:10<00:18, 14.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 230/500 | Return: -66.0 | 50-ep avg: -64.6 | Eps: 0.840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 241/500 [00:12<00:19, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 240/500 | Return: -65.0 | 50-ep avg: -64.7 | Eps: 0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|████▉     | 249/500 [00:13<00:20, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 250/500 | Return: -64.0 | 50-ep avg: -64.4 | Eps: 0.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 259/500 [00:14<00:21, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 260/500 | Return: -65.0 | 50-ep avg: -64.3 | Eps: 0.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▍    | 271/500 [00:15<00:22,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 270/500 | Return: -65.0 | 50-ep avg: -64.2 | Eps: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▌    | 281/500 [00:17<00:25,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 280/500 | Return: -67.0 | 50-ep avg: -64.3 | Eps: 0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 291/500 [00:18<00:31,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 290/500 | Return: -63.0 | 50-ep avg: -64.1 | Eps: 0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 301/500 [00:19<00:24,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 300/500 | Return: -60.0 | 50-ep avg: -63.8 | Eps: 0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 311/500 [00:21<00:22,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 310/500 | Return: -66.0 | 50-ep avg: -63.8 | Eps: 0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▍   | 321/500 [00:22<00:23,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 320/500 | Return: -61.0 | 50-ep avg: -63.4 | Eps: 0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 331/500 [00:23<00:28,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 330/500 | Return: -66.0 | 50-ep avg: -63.4 | Eps: 0.770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 341/500 [00:25<00:22,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 340/500 | Return: -63.0 | 50-ep avg: -63.3 | Eps: 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 351/500 [00:26<00:21,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 350/500 | Return: -63.0 | 50-ep avg: -63.5 | Eps: 0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 361/500 [00:28<00:18,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 360/500 | Return: -66.0 | 50-ep avg: -63.3 | Eps: 0.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 371/500 [00:29<00:18,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 370/500 | Return: -63.0 | 50-ep avg: -63.7 | Eps: 0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|███████▌  | 381/500 [00:31<00:17,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 380/500 | Return: -61.0 | 50-ep avg: -63.2 | Eps: 0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 391/500 [00:32<00:15,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 390/500 | Return: -65.0 | 50-ep avg: -63.0 | Eps: 0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 401/500 [00:33<00:13,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 400/500 | Return: -66.0 | 50-ep avg: -62.9 | Eps: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|████████▏ | 411/500 [00:35<00:11,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 410/500 | Return: -63.0 | 50-ep avg: -62.5 | Eps: 0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|████████▍ | 421/500 [00:36<00:09,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 420/500 | Return: -64.0 | 50-ep avg: -62.6 | Eps: 0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|████████▌ | 431/500 [00:38<00:10,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 430/500 | Return: -63.0 | 50-ep avg: -62.6 | Eps: 0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 441/500 [00:39<00:09,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 440/500 | Return: -55.0 | 50-ep avg: -62.0 | Eps: 0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 451/500 [00:41<00:06,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 450/500 | Return: -61.0 | 50-ep avg: -61.8 | Eps: 0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|█████████▏| 461/500 [00:42<00:04,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 460/500 | Return: -67.0 | 50-ep avg: -62.4 | Eps: 0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 470/500 [00:45<00:09,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 470/500 | Return: -63.0 | 50-ep avg: -61.6 | Eps: 0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|█████████▌| 481/500 [00:47<00:02,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 480/500 | Return: -63.0 | 50-ep avg: -61.6 | Eps: 0.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 491/500 [00:48<00:01,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 490/500 | Return: -65.0 | 50-ep avg: -62.3 | Eps: 0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 500/500 [00:49<00:00, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 500/500 | Return: -55.0 | 50-ep avg: -62.1 | Eps: 0.645\n",
      "Training finished. Saved: agent/flappy_dqn_live.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 500\n",
    "max_steps_per_ep = 10_000\n",
    "\n",
    "moving_avg_window = 50\n",
    "ep_returns = []\n",
    "losses = []\n",
    "\n",
    "for ep in trange(num_episodes, desc=\"Training\"):\n",
    "\tstate = env.reset()\n",
    "\tep_return = 0.0\n",
    "\n",
    "\tfor t in range(max_steps_per_ep):\n",
    "\t\taction = agent.select_action(state)\n",
    "\t\tnext_state, reward, done, info = env.step(action)\n",
    "\n",
    "\t\tagent.store(state, action, reward, next_state, done)\n",
    "\t\tloss = agent.train_step()\n",
    "\t\tif loss is not None:\n",
    "\t\t\tlosses.append(loss)\n",
    "\n",
    "\t\t# autosave every 1k steps so a live viewer can reload\n",
    "\t\tif agent.total_steps % 1000 == 0:\n",
    "\t\t\tagent.save(CKPT_PATH)\n",
    "\n",
    "\t\tep_return += reward\n",
    "\t\tstate = next_state\n",
    "\t\tif done:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tep_returns.append(ep_return)\n",
    "\tif (ep + 1) % 10 == 0:\n",
    "\t\trecent = ep_returns[-moving_avg_window:]\n",
    "\t\tmavg = np.mean(recent) if recent else 0.0\n",
    "\t\tprint(f\"Ep {ep+1}/{num_episodes} | Return: {ep_return:.1f} | 50-ep avg: {mavg:.1f} | Eps: {agent.epsilon:.3f}\")\n",
    "\n",
    "# final save\n",
    "agent.save(CKPT_PATH)\n",
    "print(\"Training finished. Saved:\", CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbb775",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n",
      "\u001b[32m      6\u001b[39m losses = []\n",
      "\u001b[32m      7\u001b[39m CKPT_PATH = \u001b[33m\"\u001b[39m\u001b[33magent/flappy_dqn_live.pth\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrange\u001b[49m(num_episodes, desc=\u001b[33m\"\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[32m      9\u001b[39m \tstate = env.reset()\n",
      "\u001b[32m     10\u001b[39m \tep_return = \u001b[32m0.0\u001b[39m\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'trange' is not defined"
     ]
    }
   ],
   "source": [
    "num_episodes = 500  \n",
    "max_steps_per_ep = 10_000\n",
    "\n",
    "moving_avg_window = 50\n",
    "ep_returns = []\n",
    "losses = []\n",
    "CKPT_PATH = \"agent/flappy_dqn_live.pth\"\n",
    "for ep in trange(num_episodes, desc=\"Training\"):\n",
    "\tstate = env.reset()\n",
    "\tep_return = 0.0\n",
    "\n",
    "\tfor t in range(max_steps_per_ep):\n",
    "\t\taction = agent.select_action(state)\n",
    "\t\tnext_state, reward, done, info = env.step(action)\n",
    "\n",
    "\t\tagent.store(state, action, reward, next_state, done)\n",
    "\t\tloss = agent.train_step()\n",
    "\n",
    "\t\tif agent.total_steps % 1000 == 0:  # save every 1k steps\n",
    "\t\t\tagent.save(CKPT_PATH)\n",
    "\t\t\n",
    "\t\tif loss is not None:\n",
    "\t\t\tlosses.append(loss)\n",
    "\n",
    "\t\tep_return += reward\n",
    "\t\tstate = next_state\n",
    "\t\tif done:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tep_returns.append(ep_return)\n",
    "\n",
    "\t# Display simple stats every few episodes\n",
    "\tif (ep + 1) % 10 == 0:\n",
    "\t\trecent = ep_returns[-moving_avg_window:]\n",
    "\t\tmavg = np.mean(recent) if recent else 0.0\n",
    "\t\tprint(f\"Ep {ep+1}/{num_episodes} | Return: {ep_return:.1f} | 50-ep avg: {mavg:.1f} | Eps: {agent.epsilon:.3f}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c1d504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: agent/flappy_dqn.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = \"agent/flappy_dqn.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "agent.save(save_path)\n",
    "print(\"Saved:\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5a876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval episode reward: -72.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env.close()\n",
    "state = env.reset()\n",
    "\n",
    "total_reward = 0.0\n",
    "for _ in range(5000):\n",
    "\t# Greedy action for evaluation (no epsilon)\n",
    "\twith torch.no_grad():\n",
    "\t\tstate_t = torch.from_numpy(state).float().unsqueeze(0).to(agent.cfg.device)\n",
    "\t\tq_vals = agent.q_net(state_t)\n",
    "\t\taction = int(torch.argmax(q_vals, dim=1).item())\n",
    "\n",
    "\tnext_state, reward, done, info = env.step(action)\n",
    "\tenv.render(fps=60)\n",
    "\ttotal_reward += reward\n",
    "\tstate = next_state\n",
    "\tif done:\n",
    "\t\tbreak\n",
    "\n",
    "print(\"Eval episode reward:\", total_reward)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
